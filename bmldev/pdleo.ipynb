{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import platform\n",
    "import warnings\n",
    "import ntpath\n",
    "import sys\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from unicodedata import normalize\n",
    "from bmldev.loads import txts_to_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bibliotecas para Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == 'Linux':\n",
    "    from IPython.core.magic import register_line_cell_magic\n",
    "    from bmldev.loads import sap_to_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Dicionários úteis"
   ]
  },
  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Funções utilitárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontra_tipo(arquivo):\n",
    "    arq_txts = ['txt', 'csv']\n",
    "    \n",
    "    if arquivo is not None:\n",
    "        if isinstance(arquivo,list):\n",
    "            arquivo = arquivo[0]\n",
    "        try:\n",
    "            tipo = ntpath.basename(arquivo).split('.')[-1]\n",
    "            tipo = tipo.lower()\n",
    "\n",
    "            if 'xl' in tipo:\n",
    "                tipo = 'excel'\n",
    "            if tipo in arq_txts:\n",
    "                tipo = 'txt'\n",
    "        except:\n",
    "            raise Exception('Não foi possível encontrar o tipo do arquivo')\n",
    "            \n",
    "    return tipo\n",
    "\n",
    "def arquivo_valido(arq):\n",
    "    return '~lock' not in arq and '~$' not in arq\n",
    "\n",
    "def warning(mensagem):\n",
    "    warnings.warn(mensagem, UserWarning)\n",
    "\n",
    "def encerra(mensagem=''):\n",
    "    print('{}'.format(mensagem))\n",
    "    input('Pressione enter para sair.')\n",
    "#     sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def str_para_numero(text):\n",
    "    try:\n",
    "        # First we return None if we don't have something in the text:\n",
    "        if text is None:\n",
    "            return None\n",
    "        if isinstance(text, int) or isinstance(text, float):\n",
    "            return text\n",
    "        text = text.strip()\n",
    "        if text == \"\":\n",
    "            return None\n",
    "        # Next we get the first \"[0-9,. ]+\":\n",
    "        n = re.search(\"-?[0-9]*([,. ]?[0-9]+)+\", text).group(0)\n",
    "        n = n.strip()\n",
    "        if not re.match(\".*[0-9]+.*\", text):\n",
    "            return None\n",
    "        # Then we cut to keep only 2 symbols:\n",
    "        while \" \" in n and \",\" in n and \".\" in n:\n",
    "            index = max(n.rfind(','), n.rfind(' '), n.rfind('.'))\n",
    "            n = n[0:index]\n",
    "        n = n.strip()\n",
    "        # We count the number of symbols:\n",
    "        symbolsCount = 0\n",
    "        for current in [\" \", \",\", \".\"]:\n",
    "            if current in n:\n",
    "                symbolsCount += 1\n",
    "        # If we don't have any symbol, we do nothing:\n",
    "        if symbolsCount == 0:\n",
    "            pass\n",
    "        # With one symbol:\n",
    "        elif symbolsCount == 1:\n",
    "            # If this is a space, we just remove all:\n",
    "            if \" \" in n:\n",
    "                n = n.replace(\" \", \"\")\n",
    "            # Else we set it as a \".\" if one occurence, or remove it:\n",
    "            else:\n",
    "                theSymbol = \",\" if \",\" in n else \".\"\n",
    "                if n.count(theSymbol) > 1:\n",
    "                    n = n.replace(theSymbol, \"\")\n",
    "                else:\n",
    "                    n = n.replace(theSymbol, \".\")\n",
    "        else:\n",
    "            # Now replace symbols so the right symbol is \".\" and all left are \"\":\n",
    "            rightSymbolIndex = max(n.rfind(','), n.rfind(' '), n.rfind('.'))\n",
    "            rightSymbol = n[rightSymbolIndex:rightSymbolIndex+1]\n",
    "            if rightSymbol == \" \":\n",
    "                return parseNumber(n.replace(\" \", \"_\"))\n",
    "            n = n.replace(rightSymbol, \"R\")\n",
    "            leftSymbolIndex = max(n.rfind(','), n.rfind(' '), n.rfind('.'))\n",
    "            leftSymbol = n[leftSymbolIndex:leftSymbolIndex+1]\n",
    "            n = n.replace(leftSymbol, \"L\")\n",
    "            n = n.replace(\"L\", \"\")\n",
    "            n = n.replace(\"R\", \".\")\n",
    "        # And we cast the text to float or int:\n",
    "        n = float(n)\n",
    "        if n.is_integer():\n",
    "            return int(n)\n",
    "        else:\n",
    "            return n\n",
    "    except: pass\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_list_para_num(lista):\n",
    "    return [str_para_numero(string) for string in lista]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == 'Linux':\n",
    "    @register_line_cell_magic\n",
    "    def tentativa(linha, celula):\n",
    "        try:\n",
    "            exec(celula)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('Em:')\n",
    "            print(celula)\n",
    "            input('Pressione enter para sair')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Funções de check de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifica_nulos(df, print_cols=True, return_bool=True):\n",
    "    nulos=False\n",
    "    \n",
    "    for col in list(df.columns):\n",
    "        df_aux = df[df[col].isna()]\n",
    "        \n",
    "        if df_aux.shape[0] > 0:\n",
    "            nulos=True\n",
    "            if print_cols:\n",
    "                print('Há {} nulos na coluna: {}'.format(df_aux.shape[0], col))\n",
    "                \n",
    "    if return_bool:\n",
    "        return nulos\n",
    "\n",
    "def verifica_brancos(df, print_cols=True, return_bool=True):\n",
    "    brancos = False\n",
    "    df = df.select_dtypes(include='object')\n",
    "    \n",
    "    for col in list(df.columns):\n",
    "        df_aux = df[df[col] == '']\n",
    "        \n",
    "        if df_aux.shape[0] > 0:\n",
    "            brancos=True\n",
    "            if print_cols:\n",
    "                print('Há {} brancos na coluna: {}'.format(df_aux.shape[0], col))\n",
    "                \n",
    "    if return_bool:\n",
    "        return brancos\n",
    "            \n",
    "def verifica_duplicadas(df, print_cols=True, return_bool=True):\n",
    "    duplicadas = False\n",
    "    for col in list(df.columns):\n",
    "        df_aux = df[df[col].duplicated()]\n",
    "        \n",
    "        if df_aux.shape[0] > 0:\n",
    "            duplicadas = True\n",
    "            if print_cols:\n",
    "                print('Há duplicados na coluna: {}'.format(col))\n",
    "                \n",
    "    if return_bool:\n",
    "        return duplicadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Funções de tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converte_coluna(df, coluna, tipo, sobrescreve=False):\n",
    "    if not sobrescreve:\n",
    "        df = df.copy()\n",
    "    if coluna not in df.columns:\n",
    "        raise Exception('Coluna {} não encontrada'.format(col))\n",
    "    else:\n",
    "        try:\n",
    "            if tipo == 'data':\n",
    "                df[coluna] = pd.to_datetime(df[coluna], dayfirst=True)\n",
    "            else:\n",
    "                df[coluna] = df[coluna].astype(tipo)\n",
    "        except:\n",
    "            warning(\"Não foi possível converter a coluna '{}', para {} \".format(coluna, tipo))\n",
    "            \n",
    "        if not sobrescreve:\n",
    "            return df[coluna]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converte_tipos_colunas(df, dic_cols_tipos):\n",
    "    df = df.copy()\n",
    "    ls_itens = [tupla for tupla in list(dic_cols_tipos.items())]\n",
    "    \n",
    "    for tupla in ls_itens:\n",
    "        col,tipo = tupla\n",
    "        df[col] = converte_coluna(df, col, tipo, True)    \n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def branco_para_nan(df):\n",
    "    df = df.copy()\n",
    "    branco=['', 'nan']\n",
    "    for col in list(df.select_dtypes(include='object').columns):\n",
    "        df[col] = df[col].str.strip()\n",
    "        df[col] = df[col].apply(lambda nome: np.nan if nome in branco else nome)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_acentos(txt):\n",
    "    return normalize('NFKD', str(txt)).encode('ASCII', 'ignore').decode('ASCII')\n",
    "\n",
    "def normaliza(txt):\n",
    "    return str(txt).strip().lower().replace(' ','_').replace('.','')\n",
    "\n",
    "def normaliza_colunas(cols):\n",
    "    colunas = []\n",
    "    try:\n",
    "        cols=cols.tolist()\n",
    "    except:\n",
    "        return cols\n",
    "\n",
    "    for col in cols:\n",
    "        try:\n",
    "            colunas.append(remove_acentos(normaliza(col)))\n",
    "        except:\n",
    "            colunas.append(col)\n",
    "            \n",
    "    return colunas\n",
    "\n",
    "def renomeia_colunas(colunas):\n",
    "    return [(str(col)[0].upper() + str(col)[1:]).replace('_',' ') for col in colunas]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_arquivos(diretorio=None, palavra_chave=None, multiplas_bases=False):\n",
    "    caminho=[]\n",
    "    for arquivo in listdir(diretorio):\n",
    "        if re.search(palavra_chave, remove_acentos(arquivo), flags=re.IGNORECASE) and arquivo_valido(arquivo):\n",
    "            if diretorio:\n",
    "                caminho.append(join(diretorio,arquivo))\n",
    "            else:\n",
    "                caminho.append(arquivo)\n",
    "                \n",
    "    if len(caminho) == 0:\n",
    "        raise Exception('Palavra chave não encontrada: {}'.format(str(palavra_chave)))\n",
    "    \n",
    "    if multiplas_bases:\n",
    "        return caminho\n",
    "        \n",
    "    elif len(caminho)>1:\n",
    "        warning(\"Verifique sua palavra chave: {}, a mesma se aplica a mais de uma base\".format(str(palavra_chave)))\n",
    "        \n",
    "    return caminho[0]\n",
    "\n",
    "def leitura_dic_bases(dic_bases, normaliza=True, Linux=False):\n",
    "    dfs={}\n",
    "    for base in dic_bases:\n",
    "        print (\"Lendo base {}...\".format(base), end='') \n",
    "        \n",
    "        try:\n",
    "            if dic_bases[base]['tipo'] == 'excel':\n",
    "                dfs[base] = pd.read_excel(dic_bases[base]['caminho'], dic_bases[base]['sheet'])\n",
    "             \n",
    "            if dic_bases[base]['tipo'] == 'txt':\n",
    "                if Linux:\n",
    "                    dfs[base] = sap_to_df(dic_bases[base]['caminho'], dic_bases[base]['colunas'], delimiter=dic_bases[base]['sep'])\n",
    "                else:\n",
    "                    dfs[base] = txts_to_pd(dic_bases[base]['caminho'], dic_bases[base]['colunas'], delimiter=dic_bases[base]['sep'])\n",
    "                                \n",
    "            if normaliza:\n",
    "                dfs[base].columns = normaliza_colunas(dfs[base].columns)\n",
    "                \n",
    "            if dfs[base].shape[0] == 0:\n",
    "#                 encerra('Verificar a quantidade de colunas da base')\n",
    "                raise Exception('Número de colunas informado não é compatível com a base')\n",
    "            print('ok')\n",
    "            \n",
    "        except Exception as e:\n",
    "            encerra('Erro na base: {} \\n {}'.format(base,e))\n",
    "            raise\n",
    "            break\n",
    "            \n",
    "    return dfs\n",
    "\n",
    "def preenchedor_lista_parametros_bases(palavras_chave, tipo, preenchedor, lista_para_preencher, diretorio='bases'):\n",
    "    \n",
    "    cont_arq = len([chave for chave in palavras_chave if encontra_tipo(busca_arquivos(diretorio, chave, multiplas_bases=True)) == tipo])\n",
    "    \n",
    "    if lista_para_preencher:\n",
    "        if len(lista_para_preencher) < cont_arq:\n",
    "            diff_tam = cont_arq - len(lista_para_preencher)\n",
    "            lista_para_preencher = lista_para_preencher + [preenchedor for item in range(diff_tam)]\n",
    "            \n",
    "        return lista_para_preencher\n",
    "    \n",
    "    else:\n",
    "        lista_para_preencher = [preenchedor for item in range(cont_arq)]\n",
    "        return lista_para_preencher\n",
    "\n",
    "def cria_elemento(palavra_chave, diretorio=None, col=None, sheet_name=None, separador=None, ignora_linha=None, multiplas_bases_txt=False):\n",
    "    dic = {}\n",
    "    base_caminho = busca_arquivos(diretorio=diretorio, palavra_chave=palavra_chave, multiplas_bases=multiplas_bases_txt) \n",
    "    \n",
    "    if not isinstance(base_caminho, list):\n",
    "        base_caminho = [base_caminho]\n",
    "     \n",
    "    dic['caminho'] = base_caminho  \n",
    "    dic['tipo'] = encontra_tipo(dic['caminho'])\n",
    "  \n",
    "    if dic['tipo'] == 'txt':\n",
    "        dic['colunas'] = col\n",
    "        dic['sep'] = separador\n",
    "        \n",
    "    if dic['tipo'] == 'excel':\n",
    "        dic['caminho'] = base_caminho[0]\n",
    "        dic['sheet'] = sheet_name\n",
    "#         dic['ignora_linha_col'] = ignora_linha\n",
    "\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Função cria_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_dfs(nomes_bases=[], palavras_chave=[], cols=None, sheet_names=None, sep_txt=None, diretorio='bases', multiplas_bases_txt=False, normaliza_colunas=True, debug=False):\n",
    "    '''\n",
    "    Cria um dicionário, onde cada chave dá acesso a um dataframe.\n",
    "    Para leitura de bases em .txt, é usada a biblioteca bmldev.loads\n",
    "    Para leitura de bases em .xls(x), é usado a biblioteca pandas\n",
    "\n",
    "    Parametros\n",
    "    ----------\n",
    "    nomes_bases: uma lista de strings, onde cada elemento será a chave de acesso do dataframe, se associando aos outros parametros pelo indice\n",
    "\n",
    "    palavras_chave: uma lista de strings, onde cada elemento será a palavra chave para buscar o arquivo a ser lido, no diretorio definido, se associando aos outros parametros pelo indice\n",
    "\n",
    "    cols: um lista de inteiros, onde cada elemento indica o número de colunas de uma base .txt, se associando apenas as bases .txt e aos outros parametros por indice\n",
    "\n",
    "    sheet_names: uma lista de strings, onde cada elemento indica a sheet a ser considerada na leitura de uma base .xls(x),se associando apenas as bases .xls(x) e aos outros parametos por indice.\n",
    "\n",
    "    Obs: para ler mais de uma sheet de um mesmo arquivo, adicione uma novo elemento em nomes_bases, repetindo a palavra chave e adicionando um elemento em sheet_names, especificando a outra sheet\n",
    "\n",
    "    sep_txt: uma lista de strings, onde cad elemento indica o separador a ser usado para uma base .txt(.csv), se associando apenas as bases .txt e aos outros parametros por indice\n",
    "\n",
    "    ignora_linha: Implementada, mas não ativa, falar com Leo sobre\n",
    "\n",
    "    diretorio: uma string, contendo o nome da pasta a partir do dirertorio do programa. Nesse diretorio serão procurados os arquivos, utilizando os elementos da lista palavras_chave\n",
    "    *Por padrão: 'bases'\n",
    "    \n",
    "    multiplas_bases_txt: Uma lista de booleanos, onde cada elemento indica se uma base .txt está dividida em várias partes e concatena-as na leitura, se associando apenas as bases .txt e aos outros parametros por indice\n",
    "    \n",
    "    normaliza_colunas: um booleano.\n",
    "        *Por padrão: True\n",
    "        *Casos:\n",
    "            True:\n",
    "            Remove caracteres especiais dos nomes das colunas, substitui espaços por underline e letras em uppercase para lowercase\n",
    "            False:\n",
    "            Faz nada ksk\n",
    "\n",
    "    debug: um booleano, caso verdadeiro retorna um dicionário contendo os dados de leitura da bases(não retorna a bases lidas)\n",
    "    \n",
    "    Exemplo de uso\n",
    "    ----------\n",
    "\n",
    "    Reafirmando, como anteriormente explicado,os argumentos recebidos(listas), se associam pelo índice.\n",
    "    No exemplo abaixo, a função irá usar as palavras chave para buscar arquivos na pasta 'bases_2019',\n",
    "    O elemento 'vendas' de nomes_bases, será a chave de acesso do dicionário dfs, para o arquivo lido a partir da palavra_chave 'janeiro', que tem 7 colunas. É uma base .txt dividida em mais de 1 arquivo\n",
    "    O elemento 'dados' de nomes_bases, será a chave de acesso do dicionário dfs, para o arquivo lido a partir da palavra_chave 'relatorio', na sheet 'Cadastro'. É uma base .xls(x)\n",
    "\n",
    "\n",
    "    dfs = cria_dfs(\n",
    "            diretorio = 'bases_2019',\n",
    "            nomes_bases = ['vendas','dados'],\n",
    "            palavras_chave = ['janeiro','relatorio'],\n",
    "            cols = [7],\n",
    "            sheet_names = ['Cadastro'],\n",
    "            multiplas_bases_txt = [True]\n",
    "            )\n",
    "    '''\n",
    "    #Verifica o S.O.\n",
    "    linux = True if platform.system() == 'Linux' else False \n",
    "\n",
    "    dic_bases={} #Dicionário principal de bases\n",
    "    cont_txt = 0 #Contador para atribuir o n° de colunas aos arquvios .txt\n",
    "    cont_xls = 0 #Contador para atribuir o n° de colunas aos arquvios .xls(x)\n",
    "    \n",
    "    #Preenchendo listas relacionadas aos .xls(x), para iteração \n",
    "    sheet_names = preenchedor_lista_parametros_bases(palavras_chave, 'excel', 0, sheet_names, diretorio=diretorio)\n",
    "#     ignora_linha = preenchedor_lista_parametros_bases(palavras_chave, 'excel', 0, ignora_linha, diretorio=diretorio)\n",
    "    \n",
    "    #Preenchendo listas relacionadas aos .txt, para iteração\n",
    "    sep_txt = preenchedor_lista_parametros_bases(palavras_chave, 'txt', '|', sep_txt, diretorio=diretorio)\n",
    "    multiplas_bases_txt = preenchedor_lista_parametros_bases(palavras_chave, 'txt', False, multiplas_bases_txt, diretorio=diretorio)   \n",
    "    \n",
    "    #Verifica se existe um nome para cada palavra_chave\n",
    "    if len(nomes_bases) == len(palavras_chave):\n",
    "        \n",
    "        #Itera pelo tamanho da lista de palavras_chaves\n",
    "        for i in range(len(palavras_chave)):\n",
    "            \n",
    "            #Define o tipo do arquivo\n",
    "            tipo = encontra_tipo(busca_arquivos(diretorio=diretorio, palavra_chave=palavras_chave[i], multiplas_bases=True))\n",
    "            if tipo:\n",
    "                #Arquivos .txt\n",
    "                if tipo == 'txt':\n",
    "                    if cont_txt < len(cols):\n",
    "                        #Criando dicionário com as informações da base\n",
    "                        aux = cria_elemento(palavra_chave = palavras_chave[i],\n",
    "                                            diretorio = diretorio,\n",
    "                                            col = cols[cont_txt],\n",
    "                                            separador=sep_txt[cont_txt],\n",
    "                                            multiplas_bases_txt = multiplas_bases_txt[cont_txt])\n",
    "                        \n",
    "                        #Controlando iteração das bases .txt\n",
    "                        cont_txt+=1\n",
    "                        \n",
    "                    else:\n",
    "                        print('Erro nas informações do n° de colunas')\n",
    "\n",
    "                #Arquivos .xls(x)        \n",
    "                if tipo == 'excel':\n",
    "                    #Criando dicionário com as informações da base\n",
    "                    aux = cria_elemento(palavra_chave = palavras_chave[i],\n",
    "                                        diretorio = diretorio,\n",
    "                                        sheet_name = sheet_names[cont_xls])\n",
    "#                                         ignora_linha_col=ignora_linha_col[cont_xls])\n",
    "                    \n",
    "                    #Controlando iteração das bases .xls(x)\n",
    "                    cont_xls+=1\n",
    "\n",
    "                #Adicina dicinário criado ao dicionário principal    \n",
    "                dic_bases[nomes_bases[i]] = aux\n",
    "\n",
    "    else:\n",
    "         raise Exception(\"Erro, dados de entrada incorretos, quantidade de nomes precisa ser igual a de palavras chaves\")\n",
    "            \n",
    "    if debug:\n",
    "        return dic_bases\n",
    "    #Chama a função de leitura de bases a partir de dicionários, usando o dicionári0 principal de bases criado\n",
    "    return leitura_dic_bases(dic_bases, normaliza=normaliza_colunas, Linux=linux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Função le_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def le_base(diretorio=None, palavra_chave=None, sheet_name=None, skiprow=None, cols=None, separador=None, multiplas_bases_txt=False, normaliza=True):\n",
    "    \n",
    "    caminho = busca_arquivos(diretorio, palavra_chave, multiplas_bases_txt)\n",
    "    tipo = encontra_tipo(caminho)\n",
    "    linux = True if platform.system()=='Linux' else False\n",
    "    try:           \n",
    "        if tipo == 'txt':\n",
    "            if linux:\n",
    "                base = sap_to_df(caminho, cols, delimiter=separador)\n",
    "            else:\n",
    "                if not isinstance(caminho, list):\n",
    "                    caminho = [caminho]\n",
    "                base = txts_to_pd(caminho, cols, delimiter=separador)\n",
    "\n",
    "        if tipo == 'excel':\n",
    "            base = pd.read_excel(caminho, sheet_name=sheet_name, skiprow=skiprow)\n",
    "\n",
    "        if normaliza:\n",
    "            base.columns = normaliza_colunas(base.columns)\n",
    "            \n",
    "    except Exception as e:        \n",
    "        print('Erro ao ler base: ')\n",
    "        raise(e)\n",
    "\n",
    "    return base\n",
    "\n",
    "def le_base_excel(diretorio=None, palavra_chave=None, sheet_name=0, skiprow=0, normaliza=True):\n",
    "    \n",
    "    base = le_base(diretorio=diretorio, palavra_chave=palavra_chave, sheet_name=sheet_name, skiprow=skiprow, normaliza=normaliza)\n",
    "        \n",
    "    return base\n",
    "\n",
    "def le_base_txt(diretorio=None, palavra_chave=None, cols=None, multiplas_bases_txt=False, separador='|', normaliza=True): \n",
    "    \n",
    "    base = le_base(diretorio=diretorio, palavra_chave=palavra_chave, cols=cols, multiplas_bases_txt=multiplas_bases_txt, separador=separador, normaliza=normaliza)\n",
    "        \n",
    "    return base"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
